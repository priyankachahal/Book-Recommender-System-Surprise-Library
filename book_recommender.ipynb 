{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"book_recommender.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"qHMEQktejLHr","colab_type":"code","colab":{}},"cell_type":"code","source":["from surprise import *\n","import pandas as pd\n","from surprise import accuracy\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J1mkBGznjLHw","colab_type":"code","colab":{}},"cell_type":"code","source":["def create_train_test_data(train_data_split):\n","    train_df = pd.read_csv(\"../datasets/train.csv\", delimiter=\"\\t\")  # read csv into df\n","    reader = Reader(rating_scale=(1, 5))  # invoke reader instance of surprise library\n","    print(\"Done with reading training data\")\n","    if train_data_split == 1:\n","        # train_df = train_df.sample(frac=0.7)\n","        train_set_df, test_set_df = train_test_split(train_df, test_size=0.20)\n","        train_dataset = Dataset.load_from_df(train_set_df, reader)\n","        test_set_df.drop(['rating'], axis=1, inplace=True)\n","        return train_dataset, test_set_df\n","    else:\n","        train_dataset = Dataset.load_from_df(train_df, reader)\n","        train_set = train_dataset.build_full_trainset()\n","    test_df = pd.read_csv(\"../datasets/test.csv\", delimiter=\"\\t\")\n","    print(\"Done with reading test data\")\n","    return train_set, test_df"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ic2uN1EkjLHy","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_model_3(train_set, train_data_split):\n","    print(\"Started training KNNBaseline..\")\n","    '''\n","    param_grid = {'k': [15, 20, 25, 30, 40, 50, 60]}\n","    gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=5, n_jobs=5)\n","    gs.fit(train_set)\n","    print(\"Done with model 2 training\")\n","    print(gs.best_params['rmse'])\n","    knn_baseline = KNNBaseline(gs.best_params['rmse'])\n","    '''\n","    knn_baseline = KNNBaseline()\n","    if train_data_split == 1:\n","        knn_baseline.fit(train_set.build_full_trainset())\n","    else:\n","        knn_baseline.fit(train_set)\n","    print(\"Done with KNNBaseline training\")\n","    return knn_baseline"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x8r8wyjUjLH1","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_model_2(train_set, train_data_split):\n","    print(\"Started training SVD..\")\n","    '''\n","    param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.002, 0.005],\n","                  'reg_all': [0.4, 0.6]}\n","    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n","    gs.fit(train_set)\n","    print(\"Done with model 2 training\")\n","    print(gs.best_params['rmse'])\n","    svd = SVD(gs.best_params['rmse'])\n","    '''\n","    svd = SVD()\n","    if train_data_split == 1:\n","        svd.fit(train_set.build_full_trainset())\n","    else:\n","        svd.fit(train_set)\n","    print(\"Done with SVD training\")\n","    return svd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2QIbu5OtjLH5","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_model_1(train_set, train_data_split):\n","    print(\"Started training BaselineOnly..\") \n","     '''\n","    param_grid = {'bsl_options': {'method': ['als'],\n","                                  'n_epochs': [40, 50, 60],\n","                                  'reg_i': [2, 5, 8],  # lambda 2\n","                                  'reg_u': [1, 2, 3],  # lambda 3\n","                                  }\n","                  }\n","    gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=3, return_train_measures=True, n_jobs=1)\n","    gs.fit(train_set)\n","    print(\"Done with model 1 training\")\n","    print(gs.best_params['rmse'])\n","    base_line_only = BaselineOnly(gs.best_params['rmse'])\n","    '''\n","    # this is baseline configuration for optimizing the error\n","    bsl_options = {'method': 'als',  # another option is sgd\n","                   'n_epochs': 60,  # number of iterations\n","                   'reg_u': 2,  # user-regularisation parameter\n","                   'reg_i': 8  # item-regularisation parameter\n","                   }\n","    bl = BaselineOnly(bsl_options=bsl_options)\n","    if train_data_split == 1:\n","        bl.fit(train_set.build_full_trainset())\n","    else:\n","        bl.fit(train_set)\n","    print(\"Done with BaselineOnly training\")\n","    return bl"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AtzYZsrVjLH9","colab_type":"code","colab":{}},"cell_type":"code","source":["def predict_rating(test_df, model_1, model_2, model_3, train_data_split):\n","    if train_data_split == 1:\n","        if model_1 is not None:\n","            predictions_1 = model_1.test(test_df)\n","            accuracy.rmse(predictions_1, verbose=True)\n","        if model_2 is not None:\n","            predictions_2 = model_2.test(test_df)\n","            accuracy.rmse(predictions_2, verbose=True)\n","        if model_3 is not None:\n","            predictions_3 = model_3.test(test_df)\n","            accuracy.rmse(predictions_3, verbose=True)\n","    else:\n","        output_predictions_file = open('predictions.csv', 'w')\n","        output_predictions_file.write(\"user_id-book_id\" + \",\" + \"rating\" + \"\\n\")\n","        print(\"Predicting ratings..\")\n","        for i in range(0, len(test_df)):\n","            if i % 50000 == 0:\n","                print(i)\n","            rating_p1 = None\n","            rating_p2 = None\n","            rating_p3 = None\n","            output = None\n","            predicted_rating = 0.0\n","            model_count = 0\n","            if model_1 is not None:\n","                rating_p1 = model_1.predict(uid=test_df.iloc[i]['user_id'], iid=test_df.iloc[i]['book_id'])\n","                output = str(rating_p1[0]) + \"-\" + str(rating_p1[1]) + \",\"\n","                predicted_rating = predicted_rating + float(rating_p1[3])\n","                model_count = model_count + 1\n","            if model_2 is not None:\n","                rating_p2 = model_2.predict(uid=test_df.iloc[i]['user_id'], iid=test_df.iloc[i]['book_id'])\n","                output = str(rating_p2[0]) + \"-\" + str(rating_p2[1]) + \",\"\n","                predicted_rating = predicted_rating + float(rating_p2[3])\n","                model_count = model_count + 1\n","            if model_3 is not None:\n","                rating_p3 = model_3.predict(uid=test_df.iloc[i]['user_id'], iid=test_df.iloc[i]['book_id'])\n","                output = str(rating_p3[0]) + \"-\" + str(rating_p3[1]) + \",\"\n","                predicted_rating = predicted_rating + float(rating_p3[3])\n","                model_count = model_count + 1\n","            if model_count > 0:\n","                predicted_rating = str(round(float(float(predicted_rating) / float(model_count))));\n","                output = output + predicted_rating\n","            #print(rating_p1, rating_p2, rating_p3)\n","            #print(output)\n","            output_predictions_file.write(output + \"\\n\")\n","        output_predictions_file.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UnpNf-62jLIA","colab_type":"code","colab":{}},"cell_type":"code","source":["def main():\n","    train_data_split = 0\n","    train_data, test_data = create_train_test_data(train_data_split)\n","    model_1 = train_model_1(train_data, train_data_split)\n","    model_2 = train_model_2(train_data, train_data_split)\n","    model_3 = train_model_3(train_data, train_data_split)\n","    predict_rating(test_data, model_1, model_2, model_3, train_data_split)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GorB3CTFjLIC","colab_type":"code","outputId":"366dd9ba-0431-469b-f30a-30019976c726","colab":{}},"cell_type":"code","source":["main()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Done with reading training data\n","Done with reading test data\n","Started training BaselineOnly..\n","Estimating biases using als...\n","Done with BaselineOnly training\n","Started training SVD..\n","Done with SVD training\n","Started training KNNBaseline..\n","Estimating biases using als...\n","Computing the msd similarity matrix...\n","Done computing similarity matrix.\n","Done with KNNBaseline training\n","Predicting ratings..\n","0\n","50000\n","100000\n","150000\n","200000\n","250000\n"],"name":"stdout"}]},{"metadata":{"id":"LBm_T6w4jLIK","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}